{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eba955c-10f9-435a-8f5c-a4f3148214f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:47:04.712381Z",
     "iopub.status.busy": "2023-07-31T21:47:04.711940Z",
     "iopub.status.idle": "2023-07-31T21:47:04.716609Z",
     "shell.execute_reply": "2023-07-31T21:47:04.714945Z",
     "shell.execute_reply.started": "2023-07-31T21:47:04.712355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1769883-5d03-45a6-89a4-53d97a2b31cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:47:11.801528Z",
     "iopub.status.busy": "2023-07-31T21:47:11.801087Z",
     "iopub.status.idle": "2023-07-31T21:47:11.806484Z",
     "shell.execute_reply": "2023-07-31T21:47:11.805533Z",
     "shell.execute_reply.started": "2023-07-31T21:47:11.801503Z"
    }
   },
   "outputs": [],
   "source": [
    "HUGGING_FACE_API_KEY = os.environ.get(\"HUGGING_FACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d4a3cf-3aef-48a2-9d9c-c0e6f47b8ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:47:35.032925Z",
     "iopub.status.busy": "2023-07-31T21:47:35.032483Z",
     "iopub.status.idle": "2023-07-31T21:47:35.036911Z",
     "shell.execute_reply": "2023-07-31T21:47:35.035883Z",
     "shell.execute_reply.started": "2023-07-31T21:47:35.032900Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"lmsys/fastchat-t5-3b-v1.0\"\n",
    "filenames = [\n",
    "        \"pytorch_model.bin\", \"added_tokens.json\", \"config.json\", \"generation_config.json\", \n",
    "        \"special_tokens_map.json\", \"spiece.model\", \"tokenizer_config.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de36f22-0e89-4add-9c2b-bbb34c4d9d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:47:59.770152Z",
     "iopub.status.busy": "2023-07-31T21:47:59.769784Z",
     "iopub.status.idle": "2023-07-31T21:48:00.700964Z",
     "shell.execute_reply": "2023-07-31T21:48:00.700440Z",
     "shell.execute_reply.started": "2023-07-31T21:47:59.770133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\pytorch_model.bin\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\added_tokens.json\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\config.json\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\generation_config.json\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\special_tokens_map.json\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\spiece.model\n",
      "C:\\Users\\narad\\.cache\\huggingface\\hub\\models--lmsys--fastchat-t5-3b-v1.0\\snapshots\\0b1da230a891854102d749b93f7ddf1f18a81024\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "        downloaded_model_path = hf_hub_download(\n",
    "                    repo_id=model_id,\n",
    "                    filename=filename,\n",
    "                    token=HUGGING_FACE_API_KEY\n",
    "        )\n",
    "        print(downloaded_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19af057-97a1-444c-afd3-fdcd283c934e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:48:33.787858Z",
     "iopub.status.busy": "2023-07-31T21:48:33.787384Z",
     "iopub.status.idle": "2023-07-31T21:48:34.671620Z",
     "shell.execute_reply": "2023-07-31T21:48:34.670611Z",
     "shell.execute_reply.started": "2023-07-31T21:48:33.787835Z"
    }
   },
   "outputs": [],
   "source": [
    "# from utils import check_connectivity, toggle_wifi\n",
    "# import time\n",
    "\n",
    "# print(check_connectivity())\n",
    "# toggle_wifi(\"off\")\n",
    "# time.sleep(0.5)\n",
    "# print(check_connectivity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba850f47-09e6-4b3d-9042-e4df427b0f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:49:12.517620Z",
     "iopub.status.busy": "2023-07-31T21:49:12.517270Z",
     "iopub.status.idle": "2023-07-31T21:49:40.777536Z",
     "shell.execute_reply": "2023-07-31T21:49:40.777150Z",
     "shell.execute_reply.started": "2023-07-31T21:49:12.517594Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\"text2text-generation\", model=model, device=-1, tokenizer=tokenizer, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93138286-8497-4730-9da4-3f52390bd380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:49:52.818571Z",
     "iopub.status.busy": "2023-07-31T21:49:52.817832Z",
     "iopub.status.idle": "2023-07-31T21:50:03.906446Z",
     "shell.execute_reply": "2023-07-31T21:50:03.906151Z",
     "shell.execute_reply.started": "2023-07-31T21:49:52.818537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Apache Kafka is a popular open source message broker that is used for streaming data processing and streaming applications. Some of its competitors include Apache Spark, Apache Storm, Apache Flink, Apache Flume, and Apache Flink Streams.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"What are competitors to Apache Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca79ce5d-2e44-446c-a899-d9ecc4b77caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T21:50:28.502177Z",
     "iopub.status.busy": "2023-07-31T21:50:28.501810Z",
     "iopub.status.idle": "2023-07-31T21:50:33.145049Z",
     "shell.execute_reply": "2023-07-31T21:50:33.144699Z",
     "shell.execute_reply.started": "2023-07-31T21:50:28.502152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'No,   I   do   not   have   a   sister. \\n'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"\"\"My name is Mark.\n",
    "I have brothers called David and John and my best friend is Michael.\n",
    "Using only the context above. Do you know if I have a sister?    \n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
